{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Uz0IkEKTzxb"
   },
   "source": [
    "<h1 align=\"center\"><strong><font size=\"6\"> Unveiling True Skill: <br> The Soccer-Factor-Model </h1></strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DObkizE8PqoD"
   },
   "source": [
    "### What's the Soccer-Factor-Model all about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAF7JQLxPJHf"
   },
   "source": [
    "**The Inspiration**\n",
    "\n",
    "The Soccer-Factor-Model (SFM) is inspired by the academic literature on asset-pricing along the following lines:\n",
    "\n",
    "> 1. Factor Models Ã  la [Fama & French](https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-6261.1992.tb04398.x) use \"factors\" to explain the cross-section of stock returns. <br>\n",
    " --> **here**: we use \"Team-Factors\" to explain away the role of the team's strength in making a given player $i$ score a goal.\n",
    "\n",
    "> 2. There is some literature on the skill of investment fund managers that works in a similar way: \"explain away\" that proportion of a fund's returns that is related to economic fundamentals (e.g. [Coggin, Fabozzi, Rahman (1993)](https://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1993.tb04029.x); [Fama & French (2010)](https://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.2010.01598.x); [Berg & van Binsbergen (2015)](https://www.sciencedirect.com/science/article/pii/S0304405X15000628)):\n",
    "\\begin{align}\n",
    "  r_{p,t} = \\alpha_p + \\sum^N_{n=1} \\beta_n \\, f_{n,t} + \\varepsilon_{p,t}\n",
    "\\end{align} <br>\n",
    " where $r_{p,t}$ is portfolio $p$'s return in excess of the risk-free rate (e.g. short-term U.S. government bonds). $f_{n,t}$ measures the return that one could generate by following the strategy prescribed by **factor $n$**, and $\\varepsilon_{p,t}$ is a random error that is usually assumed to be mean zero. <br> The parameter of interest here is $\\mathbf{\\alpha_p}$. It is that part of a portfolio's conditional mean, that is not to be explained by the factors $f_{1,t},...,f_{N,t}$, and is a measure of the portfolio manager's **skill/ability**. Said differently: it quantifies the manager's ability to generate returns **beyond** the return you would have received by just following the investment strategy dictated by the factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **SFM** is a direct analogy to the model above, where we substitute the target (the portfolio return $r_{p,t}$) with a measure of player $i$'s *observed performance* (OP$_{i,m,s}$) in match $m$ of season $s$.\n",
    "\n",
    "**Factors** ($f = 1,...,F$, assembled in our feature matrix ($\\mathbf{X} \\in \\mathbb{R}^F$)) are intended to help us understand which part of a player's *observed performance* is due to the strength of the **team** ( $\\mathbf{X}_i \\, \\mathbf{\\beta}$ ) that player $i$ is playing for, and which proportion of **OP**$_{i}$ is due to player $i$'s **own** skill/ability ($\\alpha_i$) . In that sense, $\\alpha_i$ is our main parameter of interest as it gives us a measure of the **innate skill/ability** of player $i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### This Notebook's Extension\n",
    "\n",
    "> Using BART to model *team-strength*, as **factors** may interact in various non-linear ways.\n",
    "\n",
    "> As BART is a capable of dealing non-linearities and multicollinearity, we also augment the set of factors. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kick-Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------- USER INTERACTION -------------------------------------- #\n",
    "\n",
    "# --- Set the directory to the datafile ('SFM_data_byPlayer.csv'):\n",
    "directory_data = '../10_data'\n",
    "\n",
    "# -------------------------------------- USER INTERACTION -------------------------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diX4wHzUeKBP"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2chWjBQiisY"
   },
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preliz as pz\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- BART\n",
    "import pymc_bart as pmb\n",
    "\n",
    "pm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.style.use(\"arviz-whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 5]\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "seed = sum(map(ord, \"sfm\"))\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Load the Data ------------------- #\n",
    "\n",
    "complete_data = pd.read_csv(f\"{directory_data}/SFM_data_byPlayer.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------- SLOAN Submission --------------------- #\n",
    "factors_numeric = [\"points_diff\"]\n",
    "other_factors = [\"center\", \"home_pitch\"]\n",
    "other_factors = [\"home_pitch\"]\n",
    "factors = other_factors + factors_numeric\n",
    "\n",
    "\n",
    "# ---------------------- Feature Engineering --------------------- #\n",
    "\n",
    "# --- We already have 'goalsscored_diff', i.e. the difference in goals scored by team and opponent.\n",
    "#     But the 'rank'-version of it might also be insightful\n",
    "complete_data['goalsscored_rank_diff'] = complete_data['goalsscored_rank_team'] - complete_data['goalsscored_rank_opp']\n",
    "complete_data['goalsscored_rank_diff_woPLAYER'] = complete_data['goalsscored_rank_team_wo_player'] - complete_data['goalsscored_rank_opp']\n",
    "# --- --- How much did the player contribute to the rank-differential?\n",
    "complete_data['goalsscored_rank_diff_contribPLAYER'] = complete_data['goalsscored_rank_diff'] - complete_data['goalsscored_rank_diff_woPLAYER']\n",
    "\n",
    "# --- We already have 'goal_balance_diff', i.e. the difference in the goal-balance between team and opponent, which captures the similarity between defense-ofense between the two teams\n",
    "#     But we may also want to capture directly the discrepancy between the team's ofense and the opponents defense as we deal with strikers\n",
    "complete_data['teamOFENSE_vs_oppDEFENSE'] = complete_data['goalsscored_cum_team'] + complete_data['goalsconceded_cum_opp']\n",
    "\n",
    "# ---------------------- Collect Factors ---------------------- #\n",
    "factors_numeric = ['points_diff','goalsscored_diff','goal_balance_diff','goalsscored_share_player_team',\n",
    "                  'goalsscored_rank_diff','goalsscored_rank_diff_contribPLAYER','teamOFENSE_vs_oppDEFENSE']\n",
    "other_factors = [\"home_pitch\"]\n",
    "factors = other_factors + factors_numeric\n",
    "\n",
    "\n",
    "# --------------------- If feature engineering had introduced NAs: drop those obs --------------------- #\n",
    "\n",
    "print(f'Shape before NA drop: {complete_data.shape}')\n",
    "\n",
    "complete_data = complete_data.dropna().reset_index(drop=True)\n",
    "print(f'Shape after NA drop: {complete_data.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== Data Engineering ========================== #\n",
    "\n",
    "complete_data[\"goal\"] = complete_data[\"goal\"].astype(int)\n",
    "complete_data[\"goals_in_match\"] = complete_data[\"goals_in_match\"].astype(int)\n",
    "\n",
    "complete_data[\"kick_off\"] = pd.to_datetime(\n",
    "    complete_data[\"kick_off\"], yearfirst=True\n",
    ").dt.normalize()\n",
    "\n",
    "# compute season number for each player, ~maturity of player\n",
    "complete_data[\"season_nbr\"] = complete_data.groupby([\"name_player\"])[\n",
    "    \"season\"\n",
    "].transform(lambda x: x.factorize(sort=True)[0])\n",
    "\n",
    "# --- Compute share of games played as center or winger\n",
    "complete_data[\"share_center\"] = complete_data[\"N_games_center\"] / complete_data[\n",
    "    [\"N_games_left\", \"N_games_center\", \"N_games_right\"]\n",
    "].sum(axis=1)\n",
    "# --- Unfortunately: drop NAs...\n",
    "complete_data = complete_data.dropna(subset=\"share_center\").reset_index(drop=True)\n",
    "\n",
    "# idiosyncracy: remove Henry's last games in 2011/12\n",
    "complete_data = complete_data[\n",
    "    ~(\n",
    "        (complete_data[\"name_player\"] == \"thierry-henry\")\n",
    "        & (complete_data[\"season\"] == \"2011/12\")\n",
    "    )\n",
    "]\n",
    "\n",
    "complete_data = complete_data.sort_values([\"name_player\", \"kick_off\"]).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_ordered = complete_data[\"name_player\"].sort_values().unique()\n",
    "players_ordered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert complete_data[\"name_player\"].sort_values().unique().shape[0] == len(\n",
    "    players_ordered\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why an Ordered Categorical likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give a good look at the frequency of each count in the data. First in terms of probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data[\"goals_in_match\"].value_counts(normalize=True).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then raw counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data[\"goals_in_match\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The counts for 3+ goals are extremely rare compared to 0, 1 and 2 goals**. This means using a Poisson likelihood is not really appropriate, as the Poisson expects much higher counts on the right tail of the distribution.\n",
    "\n",
    "In this case, it makes more sense to use a **Categorical likelihood with categories $[0, 1, 2, 3+]$**. That may sound counter-intuitive, as in theory the number of goals a player can score per game has no upper bound (hence the Poisson), but in practice, we see this number exceeds 2 less than 2% of the time.\n",
    "\n",
    "As a result, lumping together any observations equal or higher to 3, and treating each of the 4 events as a distinct category, with its own probability of success, makes more sense and allows for a more sensical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lump together values >= 3\n",
    "complete_data[\"goals_cats\"] = np.where(\n",
    "    complete_data[\"goals_in_match\"] >= 3, 3, complete_data[\"goals_in_match\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (left, right) = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(12, 4))\n",
    "sns.histplot(complete_data, x=\"goals_in_match\", ax=left)\n",
    "left.set(title=\"Raw Goals\")\n",
    "sns.histplot(complete_data, x=\"goals_cats\", ax=right)\n",
    "right.set(title=\"Lumped Goals\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this virtually doesn't change anything, because the frequencies are so low for high counts. We can now implement the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplot_mosaic(\n",
    "    [\n",
    "        [\"Frequency\", \"Proportion\"],\n",
    "        [\"Cumulative Frequency\", \"Cumulative Proportion\"],\n",
    "    ],\n",
    "    figsize=(12, 6),\n",
    "    sharex=True,\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "complete_data[\"goals_cats\"].sort_values().value_counts(sort=False).plot(\n",
    "    kind=\"bar\", alpha=0.8, rot=0, ax=axes[\"Frequency\"]\n",
    ")\n",
    "axes[\"Frequency\"].set(xlabel=\"Goals\", title=\"Frequency\")\n",
    "\n",
    "complete_data[\"goals_cats\"].sort_values().value_counts(sort=False, normalize=True).plot(\n",
    "    kind=\"bar\", alpha=0.8, rot=0, ax=axes[\"Proportion\"]\n",
    ")\n",
    "axes[\"Proportion\"].set(xlabel=\"Goals\", title=\"Proportion\")\n",
    "\n",
    "complete_data[\"goals_cats\"].sort_values().value_counts(sort=False).cumsum().plot(\n",
    "    marker=\"o\", rot=0, ax=axes[\"Cumulative Frequency\"]\n",
    ")\n",
    "axes[\"Cumulative Frequency\"].set(xlabel=\"Goals\", title=\"Cumulative Frequency\")\n",
    "\n",
    "complete_data[\"goals_cats\"].sort_values().value_counts(\n",
    "    sort=False, normalize=True\n",
    ").cumsum().plot(marker=\"o\", rot=0, ax=axes[\"Cumulative Proportion\"])\n",
    "axes[\"Cumulative Proportion\"].set(xlabel=\"Goals\", title=\"Cumulative Proportion\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data[\"goals_cats\"].sort_values().value_counts(sort=False).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data[\"goals_cats\"].sort_values().value_counts(sort=False, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_numeric_train = complete_data[factors_numeric]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler on the training data and transform the data\n",
    "factors_numeric_sdz = pd.DataFrame(\n",
    "    scaler.fit_transform(factors_numeric_train), columns=factors_numeric\n",
    ")\n",
    "\n",
    "# Add the non-numeric factor to the standardized DataFrame\n",
    "factors_sdz = factors_numeric_sdz.copy()\n",
    "#factors_sdz[other_factors] = complete_data[[\"share_center\", \"home_pitch\"]]\n",
    "factors_sdz[other_factors] = complete_data[[\"home_pitch\"]]\n",
    "\n",
    "# make sure the order is the same as the PyMC coords later on\n",
    "factors_sdz = factors_sdz[factors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_numeric_sdz.hist(alpha=0.6, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSGP Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model below, we use a linear trend on the season term for each player. That's because we assume that the effects of maturity, as we call it, are mostly non-linear for each player: all else being equal, we don't expect players to _suddenly_ become very good or very bad.\n",
    "\n",
    "Once we've taken this trend into account though, we do envision possibilities for the goal performance of a player to exhibit non-linear fluctuations (they got injured and don't come back well; they didn't prepare well enough during the summer and lag behind in the second half of the season; on the contrary, they prepared too strongly during the summer and are exhausted once Spring arrives, etc.).\n",
    "\n",
    "To handle these effects, we'll use the new [Hilbert-Space decomposition](https://arxiv.org/abs/2004.11408) of the Gaussian Process (HSGP), which is also [available in PyMC](https://www.pymc.io/projects/docs/en/stable/api/gp/generated/pymc.gp.HSGP.html). So instead of using a classic linear trend on `days_since_first_week` (as we do on `season`), we'll use an HSGP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the approximation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSGP is mainly defined by two parameters, `m` and `c`, respectively the number of basis vectors and the multiplier determining the boundary of the approximation (see [this](https://www.pymc.io/projects/examples/en/latest/gaussian_processes/HSGP-Basic.html) for more details). PyMC actually has a helper function to help us choose `m` and `c`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.gameday.hist(alpha=0.6, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.season_nbr.hist(alpha=0.6, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_within, c_within = pm.gp.hsgp_approx.approx_hsgp_hyperparams(\n",
    "    x_range=[0, complete_data.gameday.max()],\n",
    "    lengthscale_range=[5, 25],\n",
    "    cov_func=\"matern52\",\n",
    ")\n",
    "\n",
    "print(\"Recommended smallest number of basis vectors (m):\", m_within)\n",
    "print(\"Recommended smallest scaling factor (c):\", np.round(c_within, 1))\n",
    "\n",
    "m_long, c_long = pm.gp.hsgp_approx.approx_hsgp_hyperparams(\n",
    "    x_range=[0, complete_data.season_nbr.max()],\n",
    "    lengthscale_range=[2, 6],\n",
    "    cov_func=\"matern52\",\n",
    ")\n",
    "\n",
    "print(\"Recommended smallest number of basis vectors (m):\", m_long)\n",
    "print(\"Recommended smallest scaling factor (c):\", np.round(c_long, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_short_dist, _ = pz.maxent(pz.InverseGamma(), 2, 5)\n",
    "ls_medium_dist, ax = pz.maxent(pz.InverseGamma(), 15, 30)\n",
    "ax.set(title=\"Short/Mid Lengthscales Priors\", xlabel=\"days\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_long_dist, ax = pz.maxent(pz.InverseGamma(), 2, 6)\n",
    "ax.set(title=\"Long Lengthscales Priors\", xlabel=\"season\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now implement our PyMC model. It'll be a big one, but we'll take it step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define some variables we'll use throughout our model building process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these don't change between train and test\n",
    "unique_gamedays = complete_data[\"gameday\"].sort_values().unique()\n",
    "unique_seasons = complete_data[\"season_nbr\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these can change\n",
    "player_idx = pd.Categorical(\n",
    "    complete_data[\"name_player\"], categories=players_ordered\n",
    ").codes\n",
    "gameday_idx = pd.Categorical(\n",
    "    complete_data[\"gameday\"],\n",
    "    categories=unique_gamedays,\n",
    ").codes\n",
    "\n",
    "COORDS = {\n",
    "    \"event\": complete_data[\"goals_cats\"].factorize(sort=True)[1],\n",
    "    \"factor\": factors,\n",
    "    \"gameday\": unique_gamedays,\n",
    "    \"obs_id\": complete_data.index,\n",
    "    \"player\": players_ordered,\n",
    "    \"season\": unique_seasons,\n",
    "    \"timescale\": [\"short\", \"medium\", \"long\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's define the data containers for our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=COORDS) as SFM:\n",
    "\n",
    "    # Data containers\n",
    "    factor_data = pm.Data(\n",
    "        \"factor_data\", factors_sdz.to_numpy(), dims=(\"obs_id\", \"factor\")\n",
    "    )\n",
    "    gameday_id = pm.Data(\"gameday_id\", gameday_idx, dims=\"obs_id\")\n",
    "    player_id = pm.Data(\"player_id\", player_idx, dims=\"obs_id\")\n",
    "    season_id = pm.Data(\n",
    "        \"season_id\", complete_data[\"season_nbr\"].to_numpy(), dims=\"obs_id\"\n",
    "    )\n",
    "    goals_obs = pm.Data(\n",
    "        \"goals_obs\", complete_data[\"goals_cats\"].to_numpy(), dims=\"obs_id\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players' skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the priors we use [those recommendations](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SFM:\n",
    "    intercept_sigma = 5\n",
    "    sd = pm.Exponential(\"player_effect_diversity\", 1)\n",
    "\n",
    "    baseline_sigma = pt.sqrt(intercept_sigma**2 + sd**2 / len(COORDS[\"player\"]))\n",
    "    baseline = baseline_sigma * pm.Normal(\"baseline\")\n",
    "\n",
    "    player_effect = pm.Deterministic(\n",
    "        \"player_effect\",\n",
    "        baseline + pm.ZeroSumNormal(\"player_effect_raw\", sigma=sd, dims=\"player\"),\n",
    "        dims=\"player\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSGPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the HSGPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SFM:\n",
    "    X_gamedays = pm.Data(\"X_gamedays\", unique_gamedays, dims=\"gameday\")[:, None]\n",
    "    X_seasons = pm.Data(\"X_seasons\", unique_seasons, dims=\"season\")[:, None]\n",
    "\n",
    "    ## 1% chance that amplitude > 2 goals\n",
    "    alpha_scale, upper_scale = 0.01, 2.0\n",
    "    amplitude = pm.Exponential(\n",
    "        \"amplitude\", lam=-np.log(alpha_scale) / upper_scale, dims=\"timescale\"\n",
    "    )\n",
    "    ls = pm.InverseGamma(\n",
    "        \"ls\",\n",
    "        alpha=np.array([ls_short_dist.alpha, ls_medium_dist.alpha, ls_long_dist.alpha]),\n",
    "        beta=np.array([ls_short_dist.beta, ls_medium_dist.beta, ls_long_dist.beta]),\n",
    "        dims=\"timescale\",\n",
    "    )\n",
    "\n",
    "    # cov matrices\n",
    "    cov_short = amplitude[0] ** 2 * pm.gp.cov.Matern52(input_dim=1, ls=ls[0])\n",
    "    cov_medium = amplitude[1] ** 2 * pm.gp.cov.Matern52(input_dim=1, ls=ls[1])\n",
    "    cov_within = cov_short + cov_medium\n",
    "    cov_long = amplitude[2] ** 2 * pm.gp.cov.Matern52(input_dim=1, ls=ls[2])\n",
    "\n",
    "    ## GPs\n",
    "    gp_within = pm.gp.HSGP(m=[m_within], c=c_within, cov_func=cov_within)\n",
    "    basis_vectors_within, sqrt_psd_within = gp_within.prior_linearized(X=X_gamedays)\n",
    "    basis_coeffs_within = pm.Normal(\n",
    "        \"basis_coeffs_within\", shape=gp_within.n_basis_vectors\n",
    "    )\n",
    "    f_within = pm.Deterministic(\n",
    "        \"f_within\",\n",
    "        basis_vectors_within @ (basis_coeffs_within * sqrt_psd_within),\n",
    "        dims=\"gameday\",\n",
    "    )\n",
    "\n",
    "    gp_long = pm.gp.HSGP(m=[m_long], c=c_long, cov_func=cov_long)\n",
    "    basis_vectors_long, sqrt_psd_long = gp_long.prior_linearized(X=X_seasons)\n",
    "    basis_coeffs_long = pm.Normal(\"basis_coeffs_long\", shape=gp_long.n_basis_vectors)\n",
    "    f_long = pm.Deterministic(\n",
    "        \"f_long\",\n",
    "        basis_vectors_long @ (basis_coeffs_long * sqrt_psd_long),\n",
    "        dims=\"season\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression for player skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SFM:\n",
    "    alpha = pm.Deterministic(\n",
    "        \"alpha\",\n",
    "        player_effect[player_id] + f_within[gameday_id] + f_long[season_id],\n",
    "        dims=\"obs_id\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding team factors\n",
    "\n",
    "> Partially pooled across teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SFM:\n",
    "    #slope = pm.Normal(\"slope\", sigma=2.5, dims=\"factor\")\n",
    "\n",
    "    #goals_obs_CAT = pd.Categorical(complete_data[\"goals_cats\"]).codes\n",
    "    \n",
    "    # --- Here comes BART:\n",
    "    gX = pmb.BART('gX', factor_data, complete_data[\"goals_cats\"].to_numpy() ,m=20,dims='obs_id')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_probs = complete_data[\"goals_cats\"].value_counts(normalize=True).to_numpy()\n",
    "cumulative_probs = empirical_probs.cumsum()[\n",
    "    :-1\n",
    "]  # get cumulative probabilities except the last one (which will be 1)\n",
    "\n",
    "# inverse CDF of standard normal to convert to latent scale cutpoints\n",
    "cutpoints_mu_standard = norm.ppf(cumulative_probs)\n",
    "\n",
    "# Compute differences between cutpoints\n",
    "delta_prior = np.diff(cutpoints_mu_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SFM:\n",
    "    # --- Regression: add BART as the component modelling team-strength \n",
    "    eta = pm.Deterministic(\n",
    "        \"eta\", alpha + gX, dims=\"obs_id\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Hyperpriors for the differences between cutpoints (delta)\n",
    "    cutpoint_offset = 4\n",
    "    delta_mean = pm.Normal(\n",
    "        \"delta_mean\", mu=delta_prior * cutpoint_offset, sigma=1, shape=2\n",
    "    )  # Mean of differences across all players\n",
    "    delta_sigma = pm.Exponential(\n",
    "        \"delta_sigma\", 1, shape=2\n",
    "    )  # Variation of the differences\n",
    "\n",
    "    # Player-specific differences (delta)\n",
    "    delta_player = delta_mean + delta_sigma * pm.Normal(\n",
    "        \"delta_player\", shape=(len(COORDS[\"player\"]), 2)\n",
    "    )\n",
    "\n",
    "    # Cumulative sum to construct cutpoints\n",
    "    # Ensure differences are positive using softplus\n",
    "    # dims=(\"player\", \"cutpoint\")\n",
    "    cutpoints = pm.Deterministic(\n",
    "        \"cutpoints\",\n",
    "        pt.concatenate(\n",
    "            [\n",
    "                pt.full((player_effect.shape[0], 1), cutpoint_offset),\n",
    "                pt.cumsum(pt.softplus(delta_player), axis=-1) + cutpoint_offset,\n",
    "            ],\n",
    "            axis=-1,\n",
    "        ),  # Start at cutpoint_offset and sum differences\n",
    "    )\n",
    "\n",
    "    # likelihood\n",
    "    pm.OrderedLogistic(\n",
    "        \"goals_scored\",\n",
    "        cutpoints=cutpoints[player_id],\n",
    "        eta=eta,\n",
    "        observed=goals_obs,\n",
    "        dims=\"obs_id\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(SFM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Predictive Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SFM:\n",
    "    idata = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.prior = idata.prior.rename({\"goals_scored_probs_dim_1\": \"event\"})\n",
    "\n",
    "f_within_prior = idata.prior[\"f_within\"]\n",
    "f_long_prior = idata.prior[\"f_long\"]\n",
    "\n",
    "index = pd.MultiIndex.from_product(\n",
    "    [unique_seasons, unique_gamedays],\n",
    "    names=[\"season_nbr\", \"gameday\"],\n",
    ")\n",
    "unique_combinations = pd.DataFrame(index=index).reset_index()\n",
    "\n",
    "f_long_prior_aligned = f_long_prior.sel(\n",
    "    season=unique_combinations[\"season_nbr\"].to_numpy()\n",
    ").rename({\"season\": \"timestamp\"})\n",
    "f_long_prior_aligned[\"timestamp\"] = unique_combinations.index\n",
    "\n",
    "f_within_prior_aligned = f_within_prior.sel(\n",
    "    gameday=unique_combinations[\"gameday\"].to_numpy()\n",
    ").rename({\"gameday\": \"timestamp\"})\n",
    "f_within_prior_aligned[\"timestamp\"] = unique_combinations.index\n",
    "\n",
    "f_total_prior = f_long_prior_aligned + f_within_prior_aligned\n",
    "\n",
    "some_draws = rng.choice(f_total_prior.draw, size=20, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AB\n",
    "    CC\n",
    "    \"\"\",\n",
    "    figsize=(12, 7.5),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "axes[\"A\"].plot(\n",
    "    f_within_prior.gameday,\n",
    "    az.extract(f_within_prior)[\"f_within\"].isel(sample=0),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    "    label=\"random draws\",\n",
    ")\n",
    "axes[\"A\"].plot(\n",
    "    f_within_prior.gameday,\n",
    "    az.extract(f_within_prior)[\"f_within\"].isel(sample=some_draws),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=f_within_prior.gameday,\n",
    "    y=f_within_prior,\n",
    "    hdi_prob=0.83,\n",
    "    color=\"#AAC4E6\",\n",
    "    fill_kwargs={\"alpha\": 0.9, \"label\": r\"$83\\%$ HDI\"},\n",
    "    ax=axes[\"A\"],\n",
    "    smooth=False,\n",
    ")\n",
    "axes[\"A\"].plot(\n",
    "    f_within_prior.gameday,\n",
    "    f_within_prior.mean((\"chain\", \"draw\")),\n",
    "    color=\"#FBE64D\",\n",
    "    lw=2.5,\n",
    "    label=\"Mean\",\n",
    ")\n",
    "axes[\"A\"].set(\n",
    "    xlabel=\"Gameday\", ylabel=\"Nbr Goals\", title=\"Within season variation\\nShort GP\"\n",
    ")\n",
    "axes[\"A\"].legend(fontsize=10, frameon=True, ncols=3)\n",
    "\n",
    "axes[\"B\"].plot(\n",
    "    f_long_prior.season,\n",
    "    az.extract(f_long_prior)[\"f_long\"].isel(sample=some_draws),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=f_long_prior.season,\n",
    "    y=f_long_prior,\n",
    "    hdi_prob=0.83,\n",
    "    color=\"#AAC4E6\",\n",
    "    fill_kwargs={\"alpha\": 0.9},\n",
    "    ax=axes[\"B\"],\n",
    "    smooth=False,\n",
    ")\n",
    "axes[\"B\"].plot(\n",
    "    f_long_prior.season,\n",
    "    f_long_prior.mean((\"chain\", \"draw\")),\n",
    "    color=\"#FBE64D\",\n",
    "    lw=2.5,\n",
    ")\n",
    "axes[\"B\"].set(\n",
    "    xlabel=\"Season\", ylabel=\"Nbr Goals\", title=\"Across seasons variation\\nAging curve\"\n",
    ")\n",
    "\n",
    "axes[\"C\"].plot(\n",
    "    f_total_prior.timestamp,\n",
    "    az.extract(f_total_prior)[\"x\"].isel(sample=some_draws),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=f_total_prior.timestamp,\n",
    "    y=f_total_prior,\n",
    "    hdi_prob=0.83,\n",
    "    color=\"#AAC4E6\",\n",
    "    fill_kwargs={\"alpha\": 0.9},\n",
    "    ax=axes[\"C\"],\n",
    "    smooth=False,\n",
    ")\n",
    "axes[\"C\"].plot(\n",
    "    f_total_prior.timestamp,\n",
    "    f_total_prior.mean((\"chain\", \"draw\")),\n",
    "    color=\"#FBE64D\",\n",
    "    lw=2.5,\n",
    ")\n",
    "axes[\"C\"].set(xlabel=\"Timestamp\", ylabel=\"Nbr Goals\", title=\"Total GP\")\n",
    "plt.suptitle(\"Prior GPs\", fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindex_coords_original = xr.Coordinates.from_pandas_multiindex(\n",
    "    complete_data.set_index([\"name_player\", \"season\", \"gameday\"]).index,\n",
    "    \"obs_id\",\n",
    ")\n",
    "\n",
    "idata.prior = idata.prior.assign_coords(mindex_coords_original)\n",
    "idata.prior_predictive = idata.prior_predictive.assign_coords(mindex_coords_original)\n",
    "idata.observed_data = idata.observed_data.assign_coords(mindex_coords_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and convergence checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 57
    },
    "id": "w7IJ2cEwxZ1T",
    "outputId": "30f99b6e-c813-45bd-d14a-705e5723db40"
   },
   "outputs": [],
   "source": [
    "# --- In the paper we use 4 chains\n",
    "# --- Just for speed: set it to 1\n",
    "N_chains = 1\n",
    "\n",
    "with SFM:\n",
    "    # --- Does not work like this with BART:\n",
    "    #idata.extend(pm.sample(nuts_sampler=\"numpyro\", target_accept=0.99, chains=N_chains))\n",
    "    # --- When using BART:\n",
    "    idata.extend(pm.sample(target_accept=0.99, chains=N_chains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SFM:\n",
    "    idata.extend(pm.sample_posterior_predictive(idata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.prior = idata.prior.reset_index(\"obs_id\")\n",
    "idata.prior_predictive = idata.prior_predictive.reset_index(\"obs_id\")\n",
    "idata.observed_data = idata.observed_data.reset_index(\"obs_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- THIS BLOWS MY STORAGE ... around 7GB\n",
    "#az.to_netcdf(idata, \"idata_complete.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    idata.sample_stats.diverging.sum().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#az.ess(idata).min().to_pandas().sort_values().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    az.summary(\n",
    "        idata,\n",
    "        var_names=[\n",
    "            \"amplitude\",\n",
    "            \"baseline\",\n",
    "            \"player_effect_diversity\",\n",
    "            \"ls\",\n",
    "            \"slope\",\n",
    "            \"delta_sigma\",\n",
    "            \"delta_mean\",\n",
    "        ],\n",
    "        round_to=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    az.ess(\n",
    "        idata,\n",
    "        var_names=[\"basis_coeffs_long\", \"basis_coeffs_within\"],\n",
    "    ).min().to_pandas().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    az.rhat(\n",
    "        idata,\n",
    "        var_names=[\"basis_coeffs_long\", \"basis_coeffs_within\"],\n",
    "    ).max().to_pandas().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "L98I2waOfLNC",
    "outputId": "1d3fc181-64f1-4078-abf4-f651c60a01a0"
   },
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    az.plot_trace(\n",
    "        idata,\n",
    "        var_names=[\"~alpha\", \"~goals_scored_probs\", \"~eta\", \"~_raw\", \"~hsgp_coeffs\"],\n",
    "        filter_vars=\"regex\",\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------- Variable Importance ---------------------------------------- #\n",
    "df_X = pd.DataFrame(factors_sdz.to_numpy(), columns=factors)\n",
    "pmb.plot_variable_importance(idata, gX, df_X, method=\"VI\", random_seed=123, plot_kwargs={'rotation':90});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-keBPJvjxZ1V",
    "outputId": "4cc8db11-c5e3-4557-999f-9eb626901f0e"
   },
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    _, axes = plt.subplot_mosaic(\n",
    "        \"\"\"\n",
    "        AB\n",
    "        \"\"\",\n",
    "        figsize=(12, 3),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "    \n",
    "    az.plot_forest(\n",
    "        [idata.prior, idata.posterior],\n",
    "        model_names=[\"Prior\", \"Posterior\"],\n",
    "        var_names=[\"slope\"],\n",
    "        combined=True,\n",
    "        ax=axes[\"A\"],\n",
    "    )\n",
    "    axes[\"A\"].axvline(c=\"grey\", ls=\"--\")\n",
    "    axes[\"A\"].set(title=\"Slopes\")\n",
    "    \n",
    "    az.plot_forest(\n",
    "        idata,\n",
    "        var_names=[\"slope\"],\n",
    "        combined=True,\n",
    "        ax=axes[\"B\"],\n",
    "    )\n",
    "    axes[\"B\"].axvline(c=\"grey\", ls=\"--\")\n",
    "    axes[\"B\"].set(title=\"Posterior only\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-keBPJvjxZ1V",
    "outputId": "4cc8db11-c5e3-4557-999f-9eb626901f0e"
   },
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    _, axes = plt.subplot_mosaic(\n",
    "        \"\"\"\n",
    "        AB\n",
    "        \"\"\",\n",
    "        figsize=(12, 4),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "    \n",
    "    az.plot_forest(\n",
    "        [idata.prior, idata.posterior],\n",
    "        model_names=[\"Prior\", \"Posterior\"],\n",
    "        var_names=[\"diversity\", \"amplitude\", \"sd_\", \"_sigma\"],\n",
    "        combined=True,\n",
    "        filter_vars=\"regex\",\n",
    "        ax=axes[\"A\"],\n",
    "    )\n",
    "    axes[\"A\"].set(title=\"Standard deviations\")\n",
    "    \n",
    "    az.plot_forest(\n",
    "        idata,\n",
    "        var_names=[\"diversity\", \"amplitude\", \"sd_\", \"_sigma\"],\n",
    "        combined=True,\n",
    "        filter_vars=\"regex\",\n",
    "        ax=axes[\"B\"],\n",
    "    )\n",
    "    axes[\"B\"].set(title=\"Posterior only\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-keBPJvjxZ1V",
    "outputId": "4cc8db11-c5e3-4557-999f-9eb626901f0e"
   },
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    _, axes = plt.subplot_mosaic(\n",
    "        \"\"\"\n",
    "        AB\n",
    "        \"\"\",\n",
    "        figsize=(12, 35),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "    \n",
    "    az.plot_forest(\n",
    "        [idata.prior, idata.posterior],\n",
    "        model_names=[\"Prior\", \"Posterior\"],\n",
    "        var_names=\"player_effect\",\n",
    "        combined=True,\n",
    "        ax=axes[\"A\"],\n",
    "    )\n",
    "    axes[\"A\"].axvline(x=idata.posterior.player_effect.mean(), c=\"grey\", ls=\"--\")\n",
    "    axes[\"A\"].set(title=\"Player effects\")\n",
    "    \n",
    "    az.plot_forest(\n",
    "        idata,\n",
    "        var_names=\"player_effect\",\n",
    "        combined=True,\n",
    "        ax=axes[\"B\"],\n",
    "    )\n",
    "    axes[\"B\"].axvline(x=idata.posterior.player_effect.mean(), c=\"grey\", ls=\"--\")\n",
    "    axes[\"B\"].set(title=\"Posterior only\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    ax = az.plot_forest(\n",
    "        [idata.prior, idata.posterior],\n",
    "        model_names=[\"Prior\", \"Posterior\"],\n",
    "        var_names=\"ls\",\n",
    "        combined=True,\n",
    "        figsize=(10, 3),\n",
    "    )\n",
    "    ax[0].set(title=\"GPs lengthscales\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    _, axes = plt.subplot_mosaic(\n",
    "        \"\"\"\n",
    "        AB\n",
    "        \"\"\",\n",
    "        figsize=(12, 70),\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "    az.plot_forest(\n",
    "        [idata.prior[\"cutpoints\"], idata.posterior[\"cutpoints\"]],\n",
    "        combined=True,\n",
    "        model_names=[\"Prior\", \"Posterior\"],\n",
    "        ax=axes[\"A\"],\n",
    "    )\n",
    "    axes[\"A\"].set(title=\"Cutpoints\")\n",
    "    az.plot_forest(\n",
    "        idata,\n",
    "        var_names=[\"cutpoints\"],\n",
    "        combined=True,\n",
    "        ax=axes[\"B\"],\n",
    "    )\n",
    "    axes[\"B\"].set(title=\"Posterior only\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    az.plot_forest(\n",
    "        [idata.prior[\"eta\"], idata.posterior[\"eta\"]],\n",
    "        combine_dims={\"chain\", \"draw\", \"obs_id\"},\n",
    "        combined=True,\n",
    "        model_names=[\"Prior\", \"Posterior\"],\n",
    "        figsize=(10, 3),\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evolution through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_long_post = idata.posterior[\"f_long\"]\n",
    "f_within_post = idata.posterior[\"f_within\"]\n",
    "\n",
    "f_long_post_aligned = f_long_post.sel(\n",
    "    season=unique_combinations[\"season_nbr\"].to_numpy()\n",
    ").rename({\"season\": \"timestamp\"})\n",
    "f_long_post_aligned[\"timestamp\"] = unique_combinations.index\n",
    "\n",
    "f_within_post_aligned = f_within_post.sel(\n",
    "    gameday=unique_combinations[\"gameday\"].to_numpy()\n",
    ").rename({\"gameday\": \"timestamp\"})\n",
    "f_within_post_aligned[\"timestamp\"] = unique_combinations.index\n",
    "\n",
    "f_total_post = f_long_post_aligned + f_within_post_aligned\n",
    "\n",
    "some_draws = rng.choice(int(N_chains*1000), size=20, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AB\n",
    "    CC\n",
    "    \"\"\",\n",
    "    figsize=(12, 7.5),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "axes[\"A\"].plot(\n",
    "    f_within_post.gameday,\n",
    "    az.extract(f_within_post)[\"f_within\"].isel(sample=0),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    "    label=\"random draws\",\n",
    ")\n",
    "axes[\"A\"].plot(\n",
    "    f_within_post.gameday,\n",
    "    az.extract(f_within_post)[\"f_within\"].isel(sample=some_draws),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=f_within_post.gameday,\n",
    "    y=f_within_post,\n",
    "    hdi_prob=0.83,\n",
    "    color=\"#AAC4E6\",\n",
    "    fill_kwargs={\"alpha\": 0.9, \"label\": r\"$83\\%$ HDI\"},\n",
    "    ax=axes[\"A\"],\n",
    "    smooth=False,\n",
    ")\n",
    "axes[\"A\"].plot(\n",
    "    f_within_post.gameday,\n",
    "    f_within_post.mean((\"chain\", \"draw\")),\n",
    "    color=\"#FBE64D\",\n",
    "    lw=2.5,\n",
    "    label=\"Mean\",\n",
    ")\n",
    "axes[\"A\"].set(\n",
    "    xlabel=\"Gameday\", ylabel=\"Nbr Goals\", title=\"Within season variation\\nShort GP\"\n",
    ")\n",
    "axes[\"A\"].legend(fontsize=10, frameon=True, ncols=3)\n",
    "\n",
    "axes[\"B\"].plot(\n",
    "    f_long_post.season,\n",
    "    az.extract(f_long_post)[\"f_long\"].isel(sample=some_draws),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=f_long_post.season,\n",
    "    y=f_long_post,\n",
    "    hdi_prob=0.83,\n",
    "    color=\"#AAC4E6\",\n",
    "    fill_kwargs={\"alpha\": 0.9},\n",
    "    ax=axes[\"B\"],\n",
    "    smooth=False,\n",
    ")\n",
    "axes[\"B\"].plot(\n",
    "    f_long_post.season,\n",
    "    f_long_post.mean((\"chain\", \"draw\")),\n",
    "    color=\"#FBE64D\",\n",
    "    lw=2.5,\n",
    ")\n",
    "axes[\"B\"].set(\n",
    "    xlabel=\"Season\", ylabel=\"Nbr Goals\", title=\"Across seasons variation\\nAging curve\"\n",
    ")\n",
    "\n",
    "axes[\"C\"].plot(\n",
    "    f_total_post.timestamp,\n",
    "    az.extract(f_total_post)[\"x\"].isel(sample=some_draws),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=f_total_post.timestamp,\n",
    "    y=f_total_post,\n",
    "    hdi_prob=0.83,\n",
    "    color=\"#AAC4E6\",\n",
    "    fill_kwargs={\"alpha\": 0.9},\n",
    "    ax=axes[\"C\"],\n",
    "    smooth=False,\n",
    ")\n",
    "axes[\"C\"].plot(\n",
    "    f_total_post.timestamp,\n",
    "    f_total_post.mean((\"chain\", \"draw\")),\n",
    "    color=\"#FBE64D\",\n",
    "    lw=2.5,\n",
    ")\n",
    "axes[\"C\"].set(xlabel=\"Timestamp\", ylabel=\"Nbr Goals\", title=\"Total GP\")\n",
    "plt.suptitle(\"Posterior GPs\", fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figA, axes = plt.subplot_mosaic(\n",
    "    \"\"\"\n",
    "    A\n",
    "    \"\"\",\n",
    "    figsize=(6, 3.75),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "axes[\"A\"].plot(\n",
    "    f_within_post.gameday,\n",
    "    az.extract(f_within_post)[\"f_within\"].isel(sample=0),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    "    label=\"random draws\",\n",
    ")\n",
    "axes[\"A\"].plot(\n",
    "    f_within_post.gameday,\n",
    "    az.extract(f_within_post)[\"f_within\"].isel(sample=some_draws),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=f_within_post.gameday,\n",
    "    y=f_within_post,\n",
    "    hdi_prob=0.83,\n",
    "    color=\"#AAC4E6\",\n",
    "    fill_kwargs={\"alpha\": 0.9, \"label\": r\"$83\\%$ HDI\"},\n",
    "    ax=axes[\"A\"],\n",
    "    smooth=False,\n",
    ")\n",
    "axes[\"A\"].plot(\n",
    "    f_within_post.gameday,\n",
    "    f_within_post.mean((\"chain\", \"draw\")),\n",
    "    color=\"#FBE64D\",\n",
    "    lw=2.5,\n",
    "    label=\"Mean\",\n",
    ")\n",
    "axes[\"A\"].set(\n",
    "    xlabel=\"Gameday\", ylabel=\"Nbr Goals\", title=\"\"\n",
    ")\n",
    "axes[\"A\"].legend(fontsize=10, frameon=True, ncols=3, loc='upper right')\n",
    "\n",
    "\n",
    "\n",
    "figB, axes = plt.subplot_mosaic(\n",
    "    \"\"\"\n",
    "    B\n",
    "    \"\"\",\n",
    "    figsize=(6, 3.75),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "axes[\"B\"].plot(\n",
    "    f_long_post.season,\n",
    "    az.extract(f_long_post)[\"f_long\"].isel(sample=some_draws),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=f_long_post.season,\n",
    "    y=f_long_post,\n",
    "    hdi_prob=0.83,\n",
    "    color=\"#AAC4E6\",\n",
    "    fill_kwargs={\"alpha\": 0.9},\n",
    "    ax=axes[\"B\"],\n",
    "    smooth=False,\n",
    ")\n",
    "axes[\"B\"].plot(\n",
    "    f_long_post.season,\n",
    "    f_long_post.mean((\"chain\", \"draw\")),\n",
    "    color=\"#FBE64D\",\n",
    "    lw=2.5,\n",
    ")\n",
    "axes[\"B\"].set(\n",
    "    xlabel=\"Season\", ylabel=\"Nbr Goals\", title=\"\"\n",
    ")\n",
    "\n",
    "\n",
    "figC, axes = plt.subplot_mosaic(\n",
    "    \"\"\"\n",
    "    C\n",
    "    \"\"\",\n",
    "    figsize=(12, 3.75),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "axes[\"C\"].plot(\n",
    "    f_total_post.timestamp,\n",
    "    az.extract(f_total_post)[\"x\"].isel(sample=some_draws),\n",
    "    color=\"#70133A\",\n",
    "    alpha=0.3,\n",
    "    lw=1.5,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=f_total_post.timestamp,\n",
    "    y=f_total_post,\n",
    "    hdi_prob=0.83,\n",
    "    color=\"#AAC4E6\",\n",
    "    fill_kwargs={\"alpha\": 0.9},\n",
    "    ax=axes[\"C\"],\n",
    "    smooth=False,\n",
    ")\n",
    "axes[\"C\"].plot(\n",
    "    f_total_post.timestamp,\n",
    "    f_total_post.mean((\"chain\", \"draw\")),\n",
    "    color=\"#FBE64D\",\n",
    "    lw=2.5,\n",
    ")\n",
    "axes[\"C\"].set(xlabel=\"Timestamp\", ylabel=\"Nbr Goals\", title=\"\")\n",
    "#plt.suptitle(\"Posterior GPs\", fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    figA.savefig('../20_figures/HSGPs_within.png')\n",
    "    figB.savefig('../20_figures/HSGPs_across.png')\n",
    "    figC.savefig('../20_figures/HSGPs_total.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAR Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SFM:\n",
    "    idata.extend(\n",
    "        pm.sample_posterior_predictive(idata, compile_kwargs={\"mode\": \"NUMBA\"})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.posterior = idata.posterior.assign_coords(mindex_coords_original)\n",
    "idata.posterior_predictive = idata.posterior_predictive.assign_coords(\n",
    "    mindex_coords_original\n",
    ")\n",
    "idata.observed_data = idata.observed_data.assign_coords(mindex_coords_original)\n",
    "\n",
    "idata.posterior = idata.posterior.rename({\"goals_scored_probs_dim_1\": \"event\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELITE_LEVEL = [\n",
    "    \"alan-shearer\",\n",
    "    \"adriano\",\n",
    "    \"alessandro-del-piero\",\n",
    "    \"andriy-shevchenko\",\n",
    "    \"antoine-griezmann\",\n",
    "    \"antonio-di-natale\",\n",
    "    \"arjen-robben\",\n",
    "    \"carlos-vela\",\n",
    "    \"chicharito\",\n",
    "    \"christian-vieri\",\n",
    "    \"ciro-immobile\",\n",
    "    \"cristiano-ronaldo\",\n",
    "    \"david-villa\",\n",
    "    \"didier-drogba\",\n",
    "    \"diego-costa\",\n",
    "    \"diego-forlan\",\n",
    "    \"dimitar-berbatov\",\n",
    "    \"dries-mertens\",\n",
    "    \"eden-hazard\",\n",
    "    \"edinson-cavani\",\n",
    "    \"erling-haaland\",\n",
    "    \"fabio-quagliarella\",\n",
    "    \"fernando-torres\",\n",
    "    \"filippo-inzaghi\",\n",
    "    \"gareth-bale\",\n",
    "    \"gonzalo-higuain\",\n",
    "    \"harry-kane\",\n",
    "    \"henrik-larsson\",\n",
    "    \"heung-min-son\",\n",
    "    \"iago-aspas\",\n",
    "    \"jamie-vardy\",\n",
    "    \"jermain-defoe\",\n",
    "    \"karim-benzema\",\n",
    "    \"klaas-jan-huntelaar\",\n",
    "    \"lionel-messi\",\n",
    "    \"lorenzo-insigne\",\n",
    "    \"luca-toni\",\n",
    "    \"luis-suarez-2\",\n",
    "    \"mario-gomez\",\n",
    "    \"mario-mandzukic\",\n",
    "    \"michael-owen\",\n",
    "    \"miroslav-klose\",\n",
    "    \"mohamed-salah\",\n",
    "    \"neymar\",\n",
    "    \"olivier-giroud\",\n",
    "    \"paulo-dybala\",\n",
    "    \"pierre-emerick-aubameyang\",\n",
    "    \"raul\",\n",
    "    \"robert-lewandowski\",\n",
    "    \"roberto-firmino\",\n",
    "    \"robin-van-persie\",\n",
    "    \"romelu-lukaku\",\n",
    "    \"ronaldinho\",\n",
    "    \"ronaldo\",\n",
    "    \"ruud-van-nistelrooy\",\n",
    "    \"samuel-etoo\",\n",
    "    \"sergio-aguero\",\n",
    "    \"thierry-henry\",\n",
    "    \"wayne-rooney\",\n",
    "    \"zlatan-ibrahimovic\",\n",
    "]\n",
    "REPLACEMENT_LEVEL = [\n",
    "    \"adam-szalai\",\n",
    "    \"adrian-lopez\",\n",
    "    \"ailton\",\n",
    "    \"alberto-gilardino\",\n",
    "    \"alberto-paloschi\",\n",
    "    \"alexander-zickler\",\n",
    "    \"alvaro-morata\",\n",
    "    \"andre-silva\",\n",
    "    \"aritz-aduriz\",\n",
    "    \"arkadiusz-milik\",\n",
    "    \"bafetimbi-gomis\",\n",
    "    \"bobby-zamora\",\n",
    "    \"carlos-bacca\",\n",
    "    \"carsten-jancker\",\n",
    "    \"christian-benteke\",\n",
    "    \"clint-dempsey\",\n",
    "    \"craig-bellamy\",\n",
    "    \"david-nugent\",\n",
    "    \"diego-milito\",\n",
    "    \"ebbe-sand\",\n",
    "    \"emanuele-giaccherini\",\n",
    "    \"emile-heskey\",\n",
    "    \"emile-mpenza\",\n",
    "    \"eric-maxim-choupo-moting\",\n",
    "    \"fernando-llorente\",\n",
    "    \"giampaolo-pazzini\",\n",
    "    \"giovane-elber\",\n",
    "    \"giovani-dos-santos\",\n",
    "    \"graziano-pelle\",\n",
    "    \"hatem-ben-arfa\",\n",
    "    \"helder-postiga\",\n",
    "    \"hugo-almeida\",\n",
    "    \"inaki-williams\",\n",
    "    \"ivica-olic\",\n",
    "    \"jackson\",\n",
    "    \"jimmy-briand\",\n",
    "    \"joao-felix\",\n",
    "    \"johan-elmander\",\n",
    "    \"john-carew\",\n",
    "    \"john-guidetti\",\n",
    "    \"jon-dahl-tomasson\",\n",
    "    \"jonathan-soriano\",\n",
    "    \"jose-antonio-reyes\",\n",
    "    \"joseba-llorente\",\n",
    "    \"joselu\",\n",
    "    \"jozy-altidore\",\n",
    "    \"julian-schieber\",\n",
    "    \"kenny-miller\",\n",
    "    \"leon-best\",\n",
    "    \"lucas-barrios\",\n",
    "    \"luis-fabiano\",\n",
    "    \"lukas-podolski\",\n",
    "    \"manu-del-moral\",\n",
    "    \"marco-borriello\",\n",
    "    \"marcus-berg\",\n",
    "    \"marek-mintal\",\n",
    "    \"mauro-icardi\",\n",
    "    \"michu\",\n",
    "    \"mladen-petric\",\n",
    "    \"niclas-fuellkrug\",\n",
    "    \"nicolas-anelka\",\n",
    "    \"nikola-kalinic\",\n",
    "    \"nils-petersen\",\n",
    "    \"nolito\",\n",
    "    \"oliver-neuville\",\n",
    "    \"pato\",\n",
    "    \"paulo-sergio\",\n",
    "    \"peter-crouch\",\n",
    "    \"raul-jimenez\",\n",
    "    \"ricardo-quaresma\",\n",
    "    \"robbie-keane\",\n",
    "    \"robinho\",\n",
    "    \"roy-makaay\",\n",
    "    \"sergio-garcia\",\n",
    "    \"stefan-kiessling\",\n",
    "    \"tim-cahill\",\n",
    "    \"wissam-ben-yedder\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_preds = idata.posterior_predictive.reset_index(\"obs_id\")\n",
    "rlp_perf = post_preds[\"goals_scored\"].where(\n",
    "    post_preds[\"name_player\"].isin(REPLACEMENT_LEVEL), drop=True\n",
    ")\n",
    "elite_perf = post_preds[\"goals_scored\"].where(\n",
    "    post_preds[\"name_player\"].isin(ELITE_LEVEL), drop=True\n",
    ")\n",
    "PAR = (\n",
    "    elite_perf.groupby(\"name_player\").mean(\"obs_id\") - rlp_perf.mean(\"obs_id\")\n",
    ").rename(\"PAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_forest(PAR, combined=True, figsize=(8, 12))\n",
    "ax[0].axvline(c=\"k\", ls=\"--\", alpha=0.8)\n",
    "ax[0].set(\n",
    "    title=\"Performance Above Average Replacement-Level Player (PAR)\", xlabel=\"Goals\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From equal teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SFM:\n",
    "    # all teams are equal\n",
    "    pm.set_data({\"factor_data\": np.zeros_like(factors_sdz)})\n",
    "\n",
    "    counterfact_preds = pm.sample_posterior_predictive(\n",
    "        idata,\n",
    "        var_names=[\"goals_scored\"],\n",
    "        predictions=True,\n",
    "        #compile_kwargs={\"mode\": \"NUMBA\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfact_preds.predictions = counterfact_preds.predictions.assign_coords(\n",
    "    mindex_coords_original\n",
    ")\n",
    "\n",
    "preds = counterfact_preds.predictions[\"goals_scored\"].reset_index(\"obs_id\")\n",
    "rlp_perf = preds.where(preds[\"name_player\"].isin(REPLACEMENT_LEVEL), drop=True)\n",
    "elite_perf = preds.where(preds[\"name_player\"].isin(ELITE_LEVEL), drop=True)\n",
    "\n",
    "SAR = (\n",
    "    elite_perf.groupby(\"name_player\").mean(\"obs_id\") - rlp_perf.mean(\"obs_id\")\n",
    ").rename(\"SAR\")\n",
    "diff = SAR - PAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAYER_SUBSET = [\n",
    "    \"alan-shearer\",\n",
    "    \"andriy-shevchenko\",\n",
    "    \"cristiano-ronaldo\",\n",
    "    \"eden-hazard\",\n",
    "    \"erling-haaland\",\n",
    "    \"falcao\",\n",
    "    \"harry-kane\",\n",
    "    \"lionel-messi\",\n",
    "    \"ronaldinho\",\n",
    "    \"ronaldo\",\n",
    "    \"thierry-henry\",\n",
    "    \"wayne-rooney\",\n",
    "]\n",
    "SAR_plot = SAR.where(SAR[\"name_player\"].isin(PLAYER_SUBSET), drop=True).rename(\"\")\n",
    "diff_plot = diff.where(diff[\"name_player\"].isin(PLAYER_SUBSET), drop=True).rename(\"\")\n",
    "\n",
    "SAR_mean = SAR_plot.mean((\"chain\", \"draw\"))\n",
    "\n",
    "# sort indices based on means in descending order\n",
    "sorted_indices = np.argsort(-SAR_mean.to_numpy())\n",
    "\n",
    "# reorder based on sorted indices\n",
    "sorted_SAR_plot = SAR_plot.isel(name_player=sorted_indices)\n",
    "sorted_SAR_plot[\"name_player\"] = sorted_SAR_plot.name_player.str.replace(\n",
    "    \"-\", \" \"\n",
    ").str.title()\n",
    "sorted_diff_plot = diff_plot.isel(name_player=sorted_indices)\n",
    "sorted_diff_plot[\"name_player\"] = sorted_diff_plot.name_player.str.replace(\n",
    "    \"-\", \" \"\n",
    ").str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (left, right) = plt.subplots(1, 2)\n",
    "\n",
    "az.plot_forest(sorted_SAR_plot, combined=True, ax=left)\n",
    "az.plot_forest(sorted_diff_plot, combined=True, ax=right)\n",
    "\n",
    "left.axvline(c=\"k\", ls=\"--\", alpha=0.8)\n",
    "left.set(title=\"SAR: All Teams Equal\\nSorted by mean\", xlabel=\"Goals per 90\")\n",
    "right.axvline(c=\"k\", ls=\"--\", alpha=0.8)\n",
    "right.set(title=\"SAR $-$ PAR\", xlabel=\"Goals per 90\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_left, left = plt.subplots(1, 1, figsize=(6,3.75))\n",
    "\n",
    "az.plot_forest(sorted_SAR_plot, combined=True, ax=left)\n",
    "left.axvline(c=\"k\", ls=\"--\", alpha=0.8)\n",
    "left.set(title=\"\", xlabel=\"Goals per 90\")\n",
    "\n",
    "\n",
    "\n",
    "fig_right, right = plt.subplots(1, 1, figsize=(6,3.75))\n",
    "\n",
    "az.plot_forest(sorted_diff_plot, combined=True, ax=right)\n",
    "right.axvline(c=\"k\", ls=\"--\", alpha=0.8)\n",
    "right.set(title=\"\", xlabel=\"Goals per 90\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    fig_right.savefig('../20_figures/SAR_right.png')\n",
    "    fig_left.savefig('../20_figures/SAR_left.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Sample Forecast Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOO-CV vs Competitor Models\n",
    "\n",
    "1. *naive1*: player-specific $\\alpha$ + g(factors) , where ``g(X)`` is a BART-type model\n",
    "2. *naive2*: player-specific $\\alpha$ + g(factors) , where ``g(X)`` is a linear model\n",
    "4. *naive4*: player-specific $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=COORDS) as SFM_naive1:\n",
    "\n",
    "    # Data containers\n",
    "    factor_data = pm.Data(\n",
    "        \"factor_data\", factors_sdz.to_numpy(), dims=(\"obs_id\", \"factor\")\n",
    "    )\n",
    "    player_id = pm.Data(\"player_id\", player_idx, dims=\"obs_id\")\n",
    "    goals_obs = pm.Data(\n",
    "        \"goals_obs\", complete_data[\"goals_cats\"].to_numpy(), dims=\"obs_id\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # ------------------------------------- Alpha ------------------------------------- #\n",
    "    \n",
    "    # --- Prior for \"alpha\"\n",
    "    alpha = pm.Normal(\"alpha\", sigma=1, dims=\"player\")\n",
    "\n",
    "    # ------------------------------------- BART for Team-Strength ------------------------------------- #\n",
    "    \n",
    "    gX = pmb.BART('gX', factor_data, complete_data[\"goals_cats\"].to_numpy() ,m=20,dims='obs_id')\n",
    "    \n",
    "\n",
    "    # ------------------------------------- Cutpoints ------------------------------------- #\n",
    "    # Hyperpriors for the differences between cutpoints (delta)\n",
    "    cutpoint_offset = 4\n",
    "    delta_mean = pm.Normal(\n",
    "        \"delta_mean\", mu=delta_prior * cutpoint_offset, sigma=1, shape=2\n",
    "    )  # Mean of differences across all players\n",
    "    delta_sigma = pm.Exponential(\n",
    "        \"delta_sigma\", 1, shape=2\n",
    "    )  # Variation of the differences\n",
    "\n",
    "    # Player-specific differences (delta)\n",
    "    delta_player = delta_mean + delta_sigma * pm.Normal(\n",
    "        \"delta_player\", shape=(len(COORDS[\"player\"]), 2)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Cumulative sum to construct cutpoints\n",
    "    # Ensure differences are positive using softplus\n",
    "    # dims=(\"player\", \"cutpoint\")\n",
    "    cutpoints = pm.Deterministic(\n",
    "        \"cutpoints\",\n",
    "        pt.concatenate(\n",
    "            [\n",
    "                pt.full((len(COORDS[\"player\"]), 1), cutpoint_offset),\n",
    "                pt.cumsum(pt.softplus(delta_player), axis=-1) + cutpoint_offset,\n",
    "            ],\n",
    "            axis=-1,\n",
    "        ),  # Start at cutpoint_offset and sum differences\n",
    "    )\n",
    "\n",
    "\n",
    "    # ------------------------------------- Build the Conditional Mean ------------------------------------- #\n",
    "    eta = pm.Deterministic(\n",
    "        \"eta\", alpha[player_id] + gX, dims=\"obs_id\"\n",
    "    )\n",
    "\n",
    "    # likelihood\n",
    "    pm.OrderedLogistic(\n",
    "        \"goals_scored\",\n",
    "        cutpoints=cutpoints[player_id],\n",
    "        eta=eta,\n",
    "        observed=goals_obs,\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "\n",
    "\n",
    "pm.model_to_graphviz(SFM_naive1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=COORDS) as SFM_naive2:\n",
    "\n",
    "    # Data containers\n",
    "    factor_data = pm.Data(\n",
    "        \"factor_data\", factors_sdz.to_numpy(), dims=(\"obs_id\", \"factor\")\n",
    "    )\n",
    "    player_id = pm.Data(\"player_id\", player_idx, dims=\"obs_id\")\n",
    "    goals_obs = pm.Data(\n",
    "        \"goals_obs\", complete_data[\"goals_cats\"].to_numpy(), dims=\"obs_id\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # ------------------------------------- Alpha ------------------------------------- #\n",
    "    \n",
    "    # --- Prior for \"alpha\"\n",
    "    alpha = pm.Normal(\"alpha\", sigma=1, dims=\"player\")\n",
    "\n",
    "    # ------------------------------------- Factor Loadings ------------------------------------- #\n",
    "    \n",
    "    # --- Prior for Factor-Coefficients\n",
    "    slope = pm.Normal(\"slope\", sigma=2.5, dims=\"factor\")\n",
    "\n",
    "    # ------------------------------------- Cutpoints ------------------------------------- #\n",
    "    # Hyperpriors for the differences between cutpoints (delta)\n",
    "    cutpoint_offset = 4\n",
    "    delta_mean = pm.Normal(\n",
    "        \"delta_mean\", mu=delta_prior * cutpoint_offset, sigma=1, shape=2\n",
    "    )  # Mean of differences across all players\n",
    "    delta_sigma = pm.Exponential(\n",
    "        \"delta_sigma\", 1, shape=2\n",
    "    )  # Variation of the differences\n",
    "\n",
    "    # Player-specific differences (delta)\n",
    "    delta_player = delta_mean + delta_sigma * pm.Normal(\n",
    "        \"delta_player\", shape=(len(COORDS[\"player\"]), 2)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Cumulative sum to construct cutpoints\n",
    "    # Ensure differences are positive using softplus\n",
    "    # dims=(\"player\", \"cutpoint\")\n",
    "    cutpoints = pm.Deterministic(\n",
    "        \"cutpoints\",\n",
    "        pt.concatenate(\n",
    "            [\n",
    "                pt.full((len(COORDS[\"player\"]), 1), cutpoint_offset),\n",
    "                pt.cumsum(pt.softplus(delta_player), axis=-1) + cutpoint_offset,\n",
    "            ],\n",
    "            axis=-1,\n",
    "        ),  # Start at cutpoint_offset and sum differences\n",
    "    )\n",
    "\n",
    "\n",
    "    # ------------------------------------- Build the Conditional Mean ------------------------------------- #\n",
    "    eta = pm.Deterministic(\n",
    "        \"eta\", alpha[player_id] + pm.math.dot(factor_data, slope), dims=\"obs_id\"\n",
    "    )\n",
    "\n",
    "    # likelihood\n",
    "    pm.OrderedLogistic(\n",
    "        \"goals_scored\",\n",
    "        cutpoints=cutpoints[player_id],\n",
    "        eta=eta,\n",
    "        observed=goals_obs,\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "\n",
    "\n",
    "pm.model_to_graphviz(SFM_naive2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=COORDS) as SFM_naive4:\n",
    "\n",
    "    # Data containers\n",
    "    player_id = pm.Data(\"player_id\", player_idx, dims=\"obs_id\")\n",
    "    goals_obs = pm.Data(\n",
    "        \"goals_obs\", complete_data[\"goals_cats\"].to_numpy(), dims=\"obs_id\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # ------------------------------------- Alpha ------------------------------------- #\n",
    "    \n",
    "    # --- Prior for \"alpha\"\n",
    "    alpha = pm.Normal(\"alpha\", sigma=1, dims=\"player\")\n",
    "\n",
    "    \n",
    "    # ------------------------------------- Cutpoints ------------------------------------- #\n",
    "    # Hyperpriors for the differences between cutpoints (delta)\n",
    "    cutpoint_offset = 4\n",
    "    delta_mean = pm.Normal(\n",
    "        \"delta_mean\", mu=delta_prior * cutpoint_offset, sigma=1, shape=2\n",
    "    )  # Mean of differences across all players\n",
    "    delta_sigma = pm.Exponential(\n",
    "        \"delta_sigma\", 1, shape=2\n",
    "    )  # Variation of the differences\n",
    "\n",
    "    # Player-specific differences (delta)\n",
    "    delta_player = delta_mean + delta_sigma * pm.Normal(\n",
    "        \"delta_player\", shape=(len(COORDS[\"player\"]), 2)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Cumulative sum to construct cutpoints\n",
    "    # Ensure differences are positive using softplus\n",
    "    # dims=(\"player\", \"cutpoint\")\n",
    "    cutpoints = pm.Deterministic(\n",
    "        \"cutpoints\",\n",
    "        pt.concatenate(\n",
    "            [\n",
    "                pt.full((len(COORDS[\"player\"]), 1), cutpoint_offset),\n",
    "                pt.cumsum(pt.softplus(delta_player), axis=-1) + cutpoint_offset,\n",
    "            ],\n",
    "            axis=-1,\n",
    "        ),  # Start at cutpoint_offset and sum differences\n",
    "    )\n",
    "\n",
    "\n",
    "    # ------------------------------------- Build the Conditional Mean ------------------------------------- #\n",
    "    eta = pm.Deterministic(\n",
    "        \"eta\", alpha[player_id], dims=\"obs_id\"\n",
    "    )\n",
    "\n",
    "    # likelihood\n",
    "    pm.OrderedLogistic(\n",
    "        \"goals_scored\",\n",
    "        cutpoints=cutpoints[player_id],\n",
    "        eta=eta,\n",
    "        observed=goals_obs,\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "\n",
    "\n",
    "pm.model_to_graphviz(SFM_naive4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== Sample from the Posterior ============================== #\n",
    "print('Sampling: naive1')\n",
    "with SFM_naive1:\n",
    "    idata_naive1 = pm.sample( target_accept=0.99, chains=1)\n",
    "print('Sampling: naive2')\n",
    "with SFM_naive2:\n",
    "    idata_naive2 = pm.sample(nuts_sampler=\"numpyro\", target_accept=0.99, chains=1)\n",
    "print('Sampling: naive4')\n",
    "with SFM_naive4:\n",
    "    idata_naive4 = pm.sample(nuts_sampler=\"numpyro\", target_accept=0.99, chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== Compute Log-Likelihood of the Models ============================== #\n",
    "if 1==2:\n",
    "    with SFM:\n",
    "        pm.compute_log_likelihood(idata)\n",
    "    \n",
    "    with SFM_naive1:\n",
    "        pm.compute_log_likelihood(idata_naive1)\n",
    "    \n",
    "    with SFM_naive2:\n",
    "        pm.compute_log_likelihood(idata_naive2)\n",
    "    \n",
    "    with SFM_naive4:\n",
    "        pm.compute_log_likelihood(idata_naive4)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== Model Comparison ============================== #\n",
    "if 1==2:\n",
    "    df_loo = az.compare({\"SFM\": idata, \"Naive (1)\": idata_naive1,\"Naive (2)\": idata_naive2, \"Naive (3)\": idata_naive4}) \n",
    "    df_loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "    az.plot_compare(df_loo, insample_dev=False, title=False, ax=ax)\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('\\nELPD', size=12)\n",
    "    ax.tick_params(which='both',labelsize=10)\n",
    "    plt.yticks(weight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    fig.savefig('../20_figures/LOOCV.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== For Compatibility: Compute Posterior Predictives for the Benchmark Models ==================== #\n",
    "\n",
    "with SFM_naive1:\n",
    "    idata_naive1.extend(pm.sample_posterior_predictive(idata_naive1))\n",
    "\n",
    "with SFM_naive2:\n",
    "    idata_naive2.extend(pm.sample_posterior_predictive(idata_naive2))\n",
    "\n",
    "with SFM_naive4:\n",
    "    idata_naive4.extend(pm.sample_posterior_predictive(idata_naive4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- USER INTERACTION --------------------------------------- #\n",
    "\n",
    "# --- Which model do you you want to evaluate? ['SFM','naive1','naive2','naive3']\n",
    "take_mod = 'naive2'\n",
    "\n",
    "# --------------------------------------- USER INTERACTION --------------------------------------- #\n",
    "\n",
    "for take_mod in ['SFM','naive1','naive2','naive3']:\n",
    "\n",
    "    if take_mod == 'SFM':\n",
    "        df = idata.copy()\n",
    "    elif take_mod == 'naive1':\n",
    "        df = idata_naive1.copy()\n",
    "    elif take_mod == 'naive2':\n",
    "        df = idata_naive2.copy()\n",
    "    elif take_mod == 'naive3':\n",
    "        df = idata_naive4.copy()\n",
    "    \n",
    "    print(f'\\n--------------------------- Selected Model: {take_mod} --------------------------- \\n')\n",
    "    y_hdi = az.hdi(df.posterior_predictive[\"goals_scored\"])\n",
    "    y_obs = df[\"observed_data\"][\"goals_scored\"].to_numpy()\n",
    "    is_within_hdi = (y_obs >= y_hdi.sel(hdi='lower')[\"goals_scored\"].to_numpy()) & (y_obs <= y_hdi.sel(hdi='higher')[\"goals_scored\"].to_numpy())\n",
    "    print(f'Posterior 94% HDIs coverage: {np.round(is_within_hdi.mean()*100,2)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------- USER INTERACTION --------------------------------------- #\n",
    "\n",
    "# --- Which model do you you want to evaluate? ['SFM','naive1','naive2','naive3']\n",
    "take_mod = 'naive2'\n",
    "\n",
    "# --------------------------------------- USER INTERACTION --------------------------------------- #\n",
    "\n",
    "for take_mod in ['SFM','naive1','naive2','naive3']:\n",
    "\n",
    "    if take_mod == 'SFM':\n",
    "        df = idata.copy()\n",
    "    elif take_mod == 'naive1':\n",
    "        df = idata_naive1.copy()\n",
    "    elif take_mod == 'naive2':\n",
    "        df = idata_naive2.copy()\n",
    "    elif take_mod == 'naive3':\n",
    "        df = idata_naive4.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "       Given a number of goals G=0,1,2,3, which proportion of the observations ``y == G`` did the model predict correctly?\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Initialize the counter\n",
    "    print(f'\\n--------------------------- Selected Model: {take_mod} --------------------------- \\n')\n",
    "    all = 0\n",
    "    all_g0 = 0\n",
    "    for i in range(4):\n",
    "        pct_per_class = np.mean(df.posterior_predictive['goals_scored'].where(df[\"observed_data\"][\"goals_scored\"].to_numpy() == i) == i).to_numpy() * 100\n",
    "        all += pct_per_class\n",
    "        if i > 0:\n",
    "            all_g0 += pct_per_class\n",
    "        print(f'Accuracy --- # of Goals = {i}: {np.round(pct_per_class,2)}%')\n",
    "    \n",
    "    print(f'\\nTotal Accuracy:         {np.round(all,2)}%')\n",
    "    print(f'Accuracy (# Goals > 0): {np.round(all_g0,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Lmef5wjBc7dq",
    "yGxvSYdxyyCv",
    "50WHVQn1n-Fc"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
